{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознование рукописных чисел с помощью Tensorflow, Keras, и готового датасета MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных и нормализация ($x \\in{[0, 1]}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование массива из матрицы в вектор - `Flatten`\n",
    "\n",
    "Полносвязный слой, состоящий из 128 нейронов с функцией активации `ReLU`\n",
    "\n",
    "Слой `Dropout` случайным образом \"выключает\" определенное количество нейронов в предыдущем слое с заданной вероятностью. Это помогает предотвратить переобучение и делает модель более устойчивой к шуму в данных.\n",
    "\n",
    "В данном случае `Dense` - будет выходным слоем, и количество нейронов соответствует количеству классов, которые модель должна предсказывать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого примера модель возвращает вектор оценок [логитов](https://developers.google.com/machine-learning/glossary?authuser=2&hl=ru#logits) или логарифмических шансов , по одному для каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `tf.nn.softmax` преобразует эти логиты в вероятности для каждого класса, где:\n",
    "\n",
    "_Логит - это логарифм отношения вероятности события к вероятности его отсутствия. Логит используется в статистике и машинном обучении для моделирования бинарных или категориальных данных, таких как прогнозирование вероятности успеха или неудачи в определенной задаче._\n",
    "\n",
    "$$ \\operatorname{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right) $$\n",
    "\n",
    "Здесь $\\ln$ обозначает натуральный логарифм, \n",
    "\n",
    "$p$ - вероятность наступления события, \n",
    "\n",
    "а $\\operatorname{logit}(p)$ - логит вероятности $p$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_Batch (пакет) - это группа примеров из набора данных, которые обрабатываются одновременно в процессе обучения нейронной сети._\n",
    "\n",
    "_Batch size (размер пакета) - это количество примеров из набора данных, которые обрабатываются одновременно в каждом пакете в процессе обучения нейронной сети._\n",
    "\n",
    "При обучении нейронной сети, данные разбиваются на пакеты определенного размера, и каждый пакет обрабатывается последовательно. Обработка пакетов позволяет нейронной сети обучаться на больших наборах данных, не требуя слишком большого объема памяти.\n",
    "\n",
    "Размер пакета может быть выбран в зависимости от доступных ресурсов, таких как объем доступной памяти и производительность оборудования, а также от требований конкретной задачи и оптимального размера пакета для этой задачи.\n",
    "\n",
    "Использование пакетов и настройка размера пакета является важным параметром при обучении нейронных сетей и может значительно повлиять на скорость обучения и качество модели.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Представляем данные в виде тензора размерности (1000, ширина, высота, количество каналов)\n",
    "data = np.zeros((1000, 32, 32, 3))\n",
    "\n",
    "# Размер пакета\n",
    "batch_size = 64\n",
    "\n",
    "# Цикл по пакетам\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    # Обработка пакета, вычисление градиентов, обновление весов\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07885265, 0.10636128, 0.15836163, 0.03822355, 0.13412826,\n",
       "        0.13133492, 0.13352184, 0.12330534, 0.06116224, 0.03474824]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
